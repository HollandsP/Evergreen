#!/usr/bin/env python3
"""
Security vulnerability demonstration for FFmpeg service.
This test demonstrates the eval() vulnerability in get_media_info().
"""

import sys
import tempfile
import json
from unittest.mock import Mock, patch

sys.path.insert(0, '/mnt/c/Users/holla/OneDrive/Desktop/CodeProjects/Evergreen')

def test_ffmpeg_eval_vulnerability():
    """Demonstrate the eval() security vulnerability in FFmpegService."""
    
    from src.services.ffmpeg_service import FFmpegService
    
    print("üîç Testing FFmpeg eval() security vulnerability...")
    
    # Create a service instance
    service = FFmpegService()
    
    # Create malicious JSON response that would exploit eval()
    malicious_json = {
        "format": {
            "duration": "10.0",
            "size": "1000000",
            "bit_rate": "8000"
        },
        "streams": [
            {
                "codec_type": "video",
                "width": 1920,
                "height": 1080,
                "r_frame_rate": "__import__('os').system('echo SECURITY_BREACH')",  # Malicious payload
                "codec_name": "h264"
            }
        ]
    }
    
    # Mock the _run_command to return our malicious JSON
    with patch.object(service, '_run_command') as mock_run:
        mock_result = Mock()
        mock_result.stdout = json.dumps(malicious_json)
        mock_run.return_value = mock_result
        
        print("‚ùå Attempting to exploit eval() vulnerability...")
        
        try:
            # This will call eval() on the malicious r_frame_rate value
            result = service.get_media_info("test.mp4")
            print("‚ùå VULNERABILITY CONFIRMED: eval() executed malicious code!")
            print(f"   Result: {result}")
            
        except Exception as e:
            print(f"‚úÖ Attack failed due to error: {e}")
            print("   This is actually good - the malicious code didn't execute")
    
    print("\nüí° SOLUTION: Replace eval() with safe parsing")
    print("   Current code: fps = eval(video_stream.get('r_frame_rate', '0/1'))")
    print("   Safe code: fps = safe_parse_fraction(video_stream.get('r_frame_rate', '0/1'))")


def demonstrate_safe_fraction_parsing():
    """Demonstrate safe fraction parsing without eval()."""
    
    def safe_parse_fraction(fraction_str):
        """Safely parse fraction string like '30/1' or '29.97'."""
        try:
            if '/' in fraction_str:
                numerator, denominator = fraction_str.split('/')
                return float(numerator) / float(denominator) if float(denominator) != 0 else 0
            else:
                return float(fraction_str)
        except (ValueError, ZeroDivisionError):
            return 0.0
    
    print("\nüîß Testing safe fraction parsing...")
    
    # Test normal cases
    test_cases = [
        "30/1",      # Normal frame rate
        "29.97",     # Decimal frame rate  
        "24000/1001", # Complex fraction
        "0/1",       # Zero case
        "invalid",   # Invalid input
        "__import__('os').system('echo hack')",  # Malicious input
    ]
    
    for test_case in test_cases:
        result = safe_parse_fraction(test_case)
        print(f"   '{test_case}' -> {result}")
    
    print("‚úÖ Safe parsing handles all cases without security risk")


def test_file_handle_leak():
    """Demonstrate file handle leak in ElevenLabs clone_voice()."""
    
    print("\nüîç Testing ElevenLabs file handle management...")
    
    from src.services.elevenlabs_client import ElevenLabsClient
    
    # Create test files
    test_files = []
    for i in range(3):
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as f:
            f.write(b"test audio data")
            test_files.append(f.name)
    
    print(f"   Created {len(test_files)} test files")
    
    # Mock the clone_voice method to show the issue
    client = ElevenLabsClient(api_key="test_key")
    
    # Show the problematic code pattern
    print("\n‚ùå PROBLEMATIC CODE PATTERN in clone_voice():")
    print("   files_data = []")
    print("   for file_path in files:")
    print("       with open(file_path, 'rb') as f:")
    print("           files_data.append(('files', (basename, f, 'audio/mpeg')))")
    print("   # File objects 'f' are stored in list but may not be properly closed!")
    print("   response = requests.post(url, files=files_data)")
    
    print("\nüí° SAFE SOLUTION:")
    print("   files_data = []")
    print("   for file_path in files:")
    print("       with open(file_path, 'rb') as f:")
    print("           files_data.append(('files', (basename, f.read(), 'audio/mpeg')))")
    print("   # Read file content immediately, then file handle is properly closed")
    
    # Cleanup
    import os
    for file_path in test_files:
        try:
            os.unlink(file_path)
        except:
            pass


if __name__ == "__main__":
    print("üö® SECURITY VULNERABILITY TESTING")
    print("=" * 50)
    
    test_ffmpeg_eval_vulnerability()
    demonstrate_safe_fraction_parsing()
    test_file_handle_leak()
    
    print("\nüö® CRITICAL SECURITY FINDINGS:")
    print("1. FFmpeg service uses eval() - allows arbitrary code execution")
    print("2. ElevenLabs service has file handle leak risk")
    print("3. Both issues need immediate fixing before production use")
    
    print("\n‚úÖ Provided safe alternatives for both vulnerabilities")